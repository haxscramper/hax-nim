import macros
import sugar
import strformat, strutils, sequtils, algorithm
import hmisc/[defensive, helpers]
import sets
import grammars

import hashes, tables, sets
export tables, sets

import lexer
export lexer


type
  LogicError = ref object of CatchableError



func topoSort[Vertex](
  verts: openarray[Vertex],
  deps: proc(vert: Vertex): seq[Hash],
  idgen: proc(vert: Vertex): Hash,
  revese: bool = true): seq[Vertex] =

  runnableExamples:
    assert @[3, 2, 1] == topoSort(
      verts = @[1, 2, 3],
      deps = proc(v: int): seq[Hash] =
                 case v:
                   of 1: @[Hash(2), Hash(3)]
                   of 2: @[Hash(3)]
                   else: @[]
    )

  static: echo "running topo sort"

  var adjList: Table[Hash, HashSet[Hash]]
  var vertData: Table[Hash, Vertex]
  var inCounts: Table[Hash, int]

  for vert in verts:
    let depsList = deps(vert)
    let vHash = idgen(vert)

    adjList[vHash] = depsList.toHashSet()
    vertData[vHash] = vert


    for dep in depsList:
      # For each dependency - increase number of items that depend on this one
      inc inCounts.mgetOrPut(dep, 0)

  let counts: seq[(Hash, int)] = adjList.mapPairs(
    (lhs in inCounts).tern((lhs, inCounts[lhs]), (lhs, 0))
  ).filterIt(it[1] == 0)

  assert counts.len > 0,
      "Graph contains no vertices that have zero in-edges"

  var noincoming: seq[Hash] = counts.mapIt(it[0])
  var sortednodes: seq[Hash]

  while noincoming.len > 0:
    let node = noincoming.pop()
    sortednodes.add node
    # For all adjacent
    for adj in toSeq(adjList[node]):
      # Remove edge `(adj, node)`
      adjList[node].excl adj
      # Decrease number of incoming edges for `adj`
      dec inCounts[adj]


      # If has no incoming
      if inCounts[adj] == 0:
        noincoming.add adj

  for vert, adj in adjList:
    if adj.len > 0:
      raise LogicError(msg: "Cannot perform topological sort on graph with cycles")

  static: echo "finished topo sort"
  debugecho "runtime finished topo sort"
  if revese:
    return sortednodes.reversed().mapIt(vertData[it])
  else:
    return sortednodes.mapIt(vertData[it])


func topoSort[Vertex](
  verts: openarray[Vertex],
  deps: proc(vert: Vertex): seq[Hash],
  revese: bool = true): seq[Vertex] =
  topoSort(verts, deps, reverse, (r) => hash(r))

# Only `kind` for token is considered while parsing - some additional
# information can be generated by lexer (string value for token,
# start/end position etc.). This information is not used in LL(1)
# parser.


proc computeFirst[TKind](patt: Patt[TKind], other: NTermSets[TKind]): FirstSet[TKind] =
  ## Generate FIRST set for `patt`
  case patt.kind:
    of pkTerm:
      result.incl patt.tok
    of pkConcat:
      result.incl computeFirst(patt.patts[0], other)
    of pkAlternative:
      for p in patt.patts:
        result.incl computeFirst(p, other)
    of pkOptional, pkZeroOrMore, pkOneOrMore:
      result.incl computeFirst(patt.opt, other)
    of pkNterm:
      result.incl other.first[patt.sym]

proc computePatt[TKind](patt: Patt[TKind], sets: NTermSets[TKind]): CompPatt[TKind] =
  ## Generate FIRST set for pattern `patt`
  echo "Generating FIRST"
  case patt.kind:
    of pkTerm:
      result = CompPatt[TKind](kind: pkTerm, tok: patt.tok)
      result.first.incl patt.tok
    of pkConcat:
      result = CompPatt[TKind](kind: pkConcat, patts: patt.patts.mapIt(computePatt(it, sets)))
      result.first.incl computeFirst(patt.patts[0], other)
    of pkAlternative:
      result = CompPatt[TKind](kind: pkConcat, patts: patt.patts.mapIt(computePatt(it, sets)))
      for p in patt.patts:
        result.first.incl computeFirst(p, other)
    of pkOptional, pkZeroOrMore, pkOneOrMore:
      result = CompPatt[TKind](kind: patt.kind, opt: patt.opt)
      result.first.incl computeFirst(patt.opt, other)
    of pkNterm:
      result = CompPatt[TKind](kind: pkNterm, sym: patt.sym)
      result.first.incl other.first[patt.sym]


template doIt(s, action: untyped): untyped =
  type Item = type((s[0]))
  for it {.inject.} in s:
    action

  s


proc necessaryTerms[TKind](rhs: Patt[TKind]): seq[NTermSym] =
  ## Generate list of nonterminals that might appear at rhs of production
  case rhs.kind:
    of pkAlternative:
      return rhs.patts.filterIt(it.kind == pkNTerm).mapIt(it.sym)
    of pkNTerm:
      return @[rhs.sym]
    of pkConcat:
      return necessaryTerms(rhs.patts[0])
    else:
      return @[]

proc computeGrammar*[TKind](g: Grammar[TKind]): CompGrammar[TKind] =
  ## Generate first/follow sets for all rules in grammar. Rules in
  ## resulting grammar are ordered based on topological sorting.
  static: echo "computing grammar"
  var sets: NTermSets[TKind]
  # Just because I can sqeeze it into <= 4 lines does not mean that it
  # is a good idea. But code above performs topological sort of the
  # shole grammar based on which terms depend on which. If there is a
  # cycle in grammar exception is thrown - it means grammar is
  # left-recursive. (REVIEW: check if left recursion cannot occur from
  # some other type of grammar)

  echo "hello"
  let sortedRules = g.rules.topoSort(
    deps = ((r) => (r.patts.necessaryTerms().mapIt(it.hash))),
    idgen = ((r) => hash(r.nterm))
  )

  for rule in sortedRules:
    let compPatt = computePatt(rule.patts, sets)
    sets.first[rule.nterm] = compPatt.first
    result.rules.add CompRule[TKind](nterm: rule.nterm, patts: compPatt)

proc newSetLiteral[T](s: set[T]): NimNode =
  ## Create new set literal
  discard

type
  CodeGenConf = object
    laIdent: string
    toksIdent: string ## Identifier name for token stream object
    parsIdent: string ## Identifier name for parser object

proc makeParseBlock[TKind](patt: CompPatt[TKind], conf: CodeGenConf): NimNode

proc makeAltBlock[TKind](alt: CompPatt[TKind], conf: CodeGenConf): NimNode =
  ## Create code block for parsing alternative pattern
  assert alt.kind == pkAlternative
  result = nnkCaseStmt.newTree(ident conf.laIdent)
  for patt in alt.patts:
    result.add nnkOfBranch(
      newSetLiteral(patt.first),
      makeParseBlock(patt)
    )

  let elseBody = quote do:
    raise CodeError(msg: "Unexpected token")

  result.add nnkElse(elsebody)

proc makeParserName(sym: NTermSym): string =
  ## Converter nonterminal name into parsing proc name
  "parse" & sym.capitalizeAscii()

proc makeTermBlock[TKind](nterm: CompPatt[TKind], conf: CodeGenConf): NimNode =
  assert nterm.patt.kind == pkNTerm
  let ntermIdent = ident(makeParserName(nterm.patt.sym))
  let lexerIdent = ident(conf.toksIdent)
  quote do:
    `ntermIdent`(`lexerIdent`)

proc makeNTermBlock[TKind](nterm: CompPatt[TKind], conf: CodeGenConf): NimNode =
  discard

proc makeConcatBlock[TKind](nterm: CompPatt[TKind], conf: CodeGenConf): NimNode =
  discard

proc makeNtoMTimesBlock[TKind](
  nterm: CompPatt[TKind], conf: CodeGenConf,
  mintimes, maxtimes: int): NimNode =
  assert nterm.patt.kind in {pkZeroOrMore, pkOneOrMore, pkOptional}

proc makeParseBlock[TKind](patt: CompPatt[TKind], conf: CodeGenConf): NimNode =
  ## Generate code block to parse pattern `patt`.
  case patt.patt.kind:
    of pkTerm:
      makeTermBlock(patt, conf)
    of pkOptional:
      makeNtoMTimesBlock(patt, conf, 0, 1)
    of pkNterm:
      makeNTermBlock(patt, conf)
    of pkAlternative:
      makeAltBlock(patt, conf)
    of pkConcat:
      makeConcatBlock(patt, conf)
    of pkZeroOrMore:
      makeNtoMTimesBlock(patt, conf, 0, -1)
    of pkOneOrMore:
      makeNtoMTimesBlock(patt, conf, 1, -1)

proc makeRuleParser[TKind](rule: CompRule[TKind], conf: CodeGenConf
                          ): tuple[decl, impl: NimNode] =
  ## Generate implementation for proc to parse rule
  let procName = rule.nterm.makeParserName()
  let toks = ident(conf.toksIdent)
  let parser = ident(conf.parsIdent)

  let decl = quote do:
    # Declare procedure to parse `rule`. `toks` is instance of token
    # stream used to get lookahead.
    proc `procName`[Tok](`toks`: var TokStream[Tok])

  let parseBody = rule.patts.makeParseBlock(conf)
  let impl = quote do:
    proc `procName`[Tok](`toks`: var TokStream[Tok]) =
      `parseBody`


proc makeGrammarParser*[TKind](
  gram: CompGrammar[TKind],
  conf: CodeGenConf =
      CodeGenConf(
        toksIdent: "toks",
        parsIdent: "pars"
      )): NimNode =

  ## Generate code for parsing grammar `gram`
  echo "Generating grammar parser implemenetation"
  for rule in gram.rules:
    let (decl, impl) = makeRuleParser(rule, conf)

    echo decl.toStrLit()
    echo impl.toStrLit()
